{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from scipy) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (1.4.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\goncalo\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.5.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.4.2\n",
      "    Uninstalling scikit-learn-1.4.2:\n",
      "      Successfully uninstalled scikit-learn-1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Goncalo\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\~-learn\\\\.libs\\\\msvcp140.dll'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn\n",
    "%pip install pandas\n",
    "%pip install scipy\n",
    "%pip install -U scikit-learn\n",
    "%pip install pycaret\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as nmp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sb\n",
    "from pycaret.classification import *\n",
    "from pycaret.datasets import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Datasets\n",
    "launches = pd.read_csv('Launches.csv')\n",
    "configs = pd.read_csv('Configs.csv')\n",
    "families = pd.read_csv('Families.csv')\n",
    "companies = pd.read_csv('Companies.csv')\n",
    "locations = pd.read_csv('Locations.csv')\n",
    "missions = pd.read_csv('Missions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our dataset is split up between 6 csv files, the dataframe must combine the data from them. For that, we will use joins and, for them to work, the data types must be correctly aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "configs['Family Id'] = configs['Family Id'].astype(int)\n",
    "\n",
    "rockets = pd.merge(configs, families, how = 'inner', on = 'Family Id')\n",
    "\n",
    "launch_data = pd.merge(launches, locations, how = 'inner', left_on = 'Location', right_on = 'Orig_Addr')\n",
    "launch_data = pd.merge(launch_data, rockets, how = 'inner', right_on = 'Config', left_on = 'Rocket Name')\n",
    "launch_data = pd.merge(launch_data, companies, how = 'inner', left_on = 'Rocket Organisation', right_on = 'Company Name')\n",
    "launch_data = pd.merge(launch_data, missions, how = 'inner', on = 'Launch Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider the dataset info and all feature present after merging all csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "launch_data.describe()\n",
    "launch_data.head()\n",
    "launch_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns such as the launch id can be ignored, as they are not useful for our analysis. Duplicate rows should also be removed, as well as rows where there is lack of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "launch_data = launch_data.drop_duplicates()\n",
    "launch_data = launch_data.dropna()\n",
    "launch_data = launch_data.drop([\"Launch Id\"], axis=\"columns\")\n",
    "launch_data = launch_data.drop([\"Family Id\"], axis=\"columns\")\n",
    "launch_data = launch_data.drop([\"No_x\"], axis=\"columns\")\n",
    "launch_data = launch_data.drop([\"No_y\"], axis=\"columns\")\n",
    "launch_data = launch_data.drop([\"Dum\"], axis=\"columns\")\n",
    "launch_data = launch_data.drop([\"Launch Year Mon\"], axis=\"columns\")\n",
    "launch_data = launch_data.drop([\"Launch Suborbital\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting bad values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_data['Price'] = launch_data['Price'].str.replace('$', '').str.replace(' million', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# Convert thrust to numeric, removing 'kN'\n",
    "launch_data['Liftoff Thrust'] = launch_data['Liftoff Thrust'].str.replace(' kN', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# Convert payload capacities to numeric, removing 'kg'\n",
    "launch_data['Payload to LEO'] = launch_data['Payload to LEO'].str.replace(' kg', '').str.replace(',', '').astype(float)\n",
    "launch_data['Payload to GTO'] = launch_data['Payload to GTO'].str.replace(' kg', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# Convert dimensions to numeric, removing 'm'\n",
    "launch_data['Rocket Height'] = launch_data['Rocket Height'].str.replace(' m', '').astype(float)\n",
    "launch_data['Fairing Diameter'] = launch_data['Fairing Diameter'].str.replace(' m', '').astype(float)\n",
    "launch_data['Fairing Height'] = launch_data['Fairing Height'].str.replace(' m', '').astype(float)\n",
    "\n",
    "# Clean success rate in families\n",
    "launch_data['Success Rate'] = launch_data['Success Rate'].str.rstrip('%').astype(float) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following plot shows, we have a very imbalanced dataset when considering this specific fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count the number of successful and unsuccessful launches\n",
    "status_counts = launch_data['Launch Status'].value_counts()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "status_counts.plot(kind='bar', color=['skyblue'])\n",
    "plt.title('Count of Successful and Unsuccessful Launches', fontsize=16)\n",
    "plt.xlabel('Launch Status', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "launch_data['Launch Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to lower its impact, there are a few approaches that can be taken into consiration. In this instance, we decided to go for under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_majority = launch_data[launch_data['Launch Status'] == 'Success']\n",
    "df_minority = launch_data[launch_data['Launch Status'] != 'Success']\n",
    "\n",
    "sample_size = int(len(df_majority)/16)\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,    # sample without replacement\n",
    "                                   n_samples=sample_size,     # match number in minority class\n",
    "                                   random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_balanced = pd.concat([df_minority, df_majority_downsampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verify the new class distribution\n",
    "balanced_status = df_balanced['Launch Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a visualization of the balanced dataset, in order to see what happens when we have a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "balanced_status.plot(kind='bar', color=['skyblue'])\n",
    "plt.title('Count of Successful and Unsuccessful Launches on Balanced Dataframe', fontsize=16)\n",
    "plt.xlabel('Launch Status', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_balanced['Launch Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Question: does the price influence the success of a Launch?\n",
    "\n",
    "Let's follow an Hypothesis Testing.\n",
    "\n",
    "Hypothesis\n",
    "1) Null Hypothesis (Ho): Price has no influence on the success of a launch.\n",
    "2) Alternative Hypothesis (Ha): Price influences positively the success of a launch. (Is there a correlation?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first run a boxplot to see the distribution of the data, check if there are any outliers and if their presence is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Launch Status', y='Rocket Price', data=df_balanced, width=0.6)\n",
    "plt.title('Rocket Price by Launch Status')\n",
    "plt.xlabel('Launch Status')\n",
    "plt.ylabel('Rocket Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot visualization suggests that rocket price is not a decisive factor in determining launch success, as failures happen across all price ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the relationship between rocket price and launch success, we conducted a point-biserial correlation test. This test is appropriate for analyzing the association between a continuous variable (rocket price) and a dichotomous variable (launch success: 0 or 1). You can know more about this specific test in the following link: https://www.statisticshowto.com/point-biserial-correlation/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rocket_prices = df_balanced['Rocket Price']\n",
    "launch_success = (df_balanced['Launch Status'] == 'Success').astype(int)\n",
    "df_balanced['Launch Success Binary'] = df_balanced['Launch Status'].apply(lambda x: 1 if x.lower() == 'success' else 0)\n",
    "\n",
    "# Calculate point-biserial correlation\n",
    "correlation, p_value = stats.pointbiserialr(launch_success, rocket_prices)\n",
    "\n",
    "print(f\"Correlation coefficient: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant relationship between rocket price and launch success.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant relationship between rocket price and launch success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show:\n",
    "\n",
    "- Correlation coefficient: -0.0107\n",
    "- P-value: 0.8834\n",
    "\n",
    "With a p-value of 0.8834, which is much larger than the conventional significance level of 0.05, we fail to reject the null hypothesis. This suggests that there is no statistically significant relationship between rocket price and launch success.\n",
    "\n",
    "The correlation coefficient of -0.0107 indicates a very weak negative relationship between price and success. However, given the high p-value, this relationship is not statistically significant and is likely due to random chance rather than a true association in the population.\n",
    "\n",
    "In conclusion, based on this point-biserial correlation test, we fail to reject the null hypothesis that there is no statistically significant relationship between rocket price and launch success. This suggests that there is no evidence to support the claim that rocket prices are directly related to launch success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Question: Is there any corporation more likely to succeed in a launch??\n",
    "\n",
    "Let's follow a Hypothesis Testing, just as in the first question.\n",
    "\n",
    "Hypothesis\n",
    "1) Null Hypothesis (Ho): A rocket's corporation has no influence on the success of a launch.\n",
    "2) Alternative Hypothesis (Ha): The corporation that fabricated the rocket influences positively the success of a launch. (Is there a correlation?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a simple groupby operation on the Launches data frame. We will group the data by the Rocket Organisation, and then count the number of Total launches for each organization, sum the number of Successful Launches, and provide the average number (Success Rate) of successful launches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Group the data by the 'Rocket Organisation' column and calculate the number of launches, successful launches, and success rate.\n",
    "success_rate = (\n",
    "    df_balanced.groupby('Rocket Organisation')['Launch Success Binary']\n",
    "    .agg(['count', 'sum', 'mean'])\n",
    "    .rename(columns={'count': 'Total Launches', 'sum': 'Successful Launches', 'mean': 'Success Rate'})\n",
    ")\n",
    "\n",
    "# Limit the data to only include organizations with at least 5 successful launches, in order to have a more meaningful analysis.\n",
    "success_rate = success_rate[success_rate['Total Launches'] >= 5]\n",
    "\n",
    "success_rate = success_rate.sort_values(by=['Success Rate'], ascending=[False])\n",
    "success_rate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a visualization to understand which is the best contender to be the top rocket organization ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(success_rate.index, success_rate['Success Rate'], color='skyblue')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.title('Top Rocket Organisations by Success Rate', fontsize=16)\n",
    "plt.xlabel('Success Rate', fontsize=12)\n",
    "plt.ylabel('Rocket Organisation', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualisation concludes that **SpaceX** is the most successful Rocket Organisation within this dataset, if we consider only the average of Successful Launches per Rocket Organisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive deeper to understand the data, and see if we can find some relationship between the Rocket's Organization and the launch success.\n",
    "\n",
    "To examine the relationship between corporation and launch success, we conducted a chi-square independence test (you can get more detailed information on this matter here: https://www.jmp.com/en_be/statistics-knowledge-portal/chi-square-test/chi-square-test-of-independence.html). This test evaluates the independence of a feature (launch success: 0 or 1) from another (corporation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df_balanced['Rocket Organisation'], df_balanced['Launch Success Binary'])\n",
    "\n",
    "# Perform the test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2:.4f}, p-value: {p:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant relationship between rocket organization and launch success.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant relationship between rocket organization and launch success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show:\n",
    "\n",
    "- Chi-square statistic: 27.7555,\n",
    "- P-value: 0.0098\n",
    "\n",
    "With a p-value of 0.0098, which is exceptionally smaller than the conventional significance level of 0.05, the null hypothesis is rejected, meaning that launch success is, in fact, dependent on the corporation.\n",
    "\n",
    "The Chi-square statistic of 27.7555 points towards a very strong relationship between corporation and success. Besides that, given the low p-value, we can confirm that this relationship is statistically significant and is likely to be a real association, not being due to chance.\n",
    "\n",
    "In conclusion, based on this chi-square test and the respective statistical value and P-value, we can conclude that organization has a meaningful influence on launch success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, however, still try to figure out which company is more likely to succeed according to both raw success rate and to residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "success_rate['Confidence Interval'] = success_rate.apply(\n",
    "    lambda row: (\n",
    "        row['Success Rate'] - 1.96 * ((row['Success Rate'] * (1 - row['Success Rate'])) / row['Total Launches'])**0.5,\n",
    "        row['Success Rate'] + 1.96 * ((row['Success Rate'] * (1 - row['Success Rate'])) / row['Total Launches'])**0.5,\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "contingency_table = pd.crosstab(df_balanced['Rocket Organisation'], df_balanced['Launch Success Binary'])\n",
    "\n",
    "# Perform the Chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = (contingency_table - expected) / np.sqrt(expected)\n",
    "\n",
    "# Sort residuals\n",
    "residuals = residuals.sum(axis=1).sort_values(ascending=False)\n",
    "print(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before concluding anything, however, we must reason about the meaning of a high or low, positive or negative residual. The residual looks to highlight, in this case, that a launch's success is more or less likely to be due to randomness and not due to the organization itself. Besides that, we must also understand that confidence intervals are meant to evaluate how consistent the impact of a feature is (in this case, the organization).\n",
    "\n",
    "After performing the calculation of confidence intervals for each organization, performing a chi-square test and calulating residuals for each enterprise, we understand that:  \n",
    "\n",
    "- If we are only taking into consideration raw success rate, SpaceX is a clear favorite succeed, as it holds an almost 78% success rate. \n",
    "- However, if we are only taking into consideration both the residuals and the confidence intervals and the consistency, VKS RF comes across as the most consistent organization even while not keeping a higher success-rate - in fact, it was consistently bad! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(\n",
    "    success_rate.index,\n",
    "    success_rate['Success Rate'],\n",
    "    yerr=[\n",
    "        success_rate['Success Rate'] - success_rate['Confidence Interval'].apply(lambda x: x[0]),\n",
    "        success_rate['Confidence Interval'].apply(lambda x: x[1]) - success_rate['Success Rate']\n",
    "    ],\n",
    "    fmt='o', capsize=5, color='skyblue', ecolor='darkblue'\n",
    ")\n",
    "plt.title('Success Rates by Corporation with 95% Confidence Intervals')\n",
    "plt.xlabel('Rocket Organisation')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Question: Is there any country more likely to succeed in a launch?\n",
    "\n",
    "Let's follow a Hypothesis Testing, just as in the first question.\n",
    "\n",
    "Hypothesis\n",
    "1) Null Hypothesis (Ho): A rocket's base country has no influence on the success of a launch.\n",
    "2) Alternative Hypothesis (Ha): The country where the rocket is fabricated influences positively the success of a launch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a simple groupby operation on the Launches data frame. We will group the data by Country, and then count the number of Total launches for each country, sum the number of Successful Launches, and provide the average number (Success Rate) of successful launches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "success_rate = (\n",
    "    df_balanced.groupby('Country')['Launch Success Binary']\n",
    "    .agg(['count', 'sum', 'mean'])\n",
    "    .rename(columns={'count': 'Total Launches', 'sum': 'Successful Launches', 'mean': 'Success Rate'})\n",
    ")\n",
    "\n",
    "success_rate = success_rate[success_rate['Total Launches'] >= 5]\n",
    "\n",
    "success_rate = success_rate.sort_values(by=['Success Rate', 'Total Launches'], ascending=[False, False])\n",
    "\n",
    "success_rate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "# Create an horizontal bar chart\n",
    "plt.barh(success_rate.index, success_rate['Success Rate'], color='skyblue')\n",
    "# Invert the y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top Rocket Organisations by Success Rate', fontsize=16)\n",
    "plt.xlabel('Success Rate', fontsize=12)\n",
    "plt.ylabel('Rocket Organisation', fontsize=12)\n",
    "# Add a grid\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualisation concludes that United States is the most successful Country within this dataset, if we consider only the average of Successful Launches per Country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive deeper to understand the data, and see if we can find some relationship between the Rocket's Home Country and the launch success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df_balanced['Country'], df_balanced['Launch Success Binary'])\n",
    "\n",
    "# Perform the test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2:.4f}, p-value: {p:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant relationship between the Country and launch success.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant relationship between the Country and the launch success.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the relationship between home country and launch success, we conducted a chi-square independence test (you can get more detailed information on this matter here: https://www.jmp.com/en_be/statistics-knowledge-portal/chi-square-test/chi-square-test-of-independence.html). This test evaluates the independence of a feature (launch success: 0 or 1) from another (country). The results show:\n",
    "\n",
    "- Chi-square statistic: 9.7005,\n",
    "- P-value: 0.0842\n",
    "\n",
    "With a p-value of 0.0842, which is bigger than the conventional significance level of 0.05, the null hypothesis cannot be rejected, meaning there's no evidence that there's a relationship between the Launch Country and having a Successful Launch. \n",
    "\n",
    "The Chi-square statistic of 9.7005 points towards a stronger relationship between country and success, even if it's not a meaningful relationship. Taking this  p-value into consideration, we can conclude that there is insufficient evidence to conclude that the observed and expected distributions are significantly different or that the variables are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, however, still try to figure out which country is more likely to succeed according to both raw success rate and to residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "success_rate['Confidence Interval'] = success_rate.apply(\n",
    "    lambda row: (\n",
    "        row['Success Rate'] - 1.96 * ((row['Success Rate'] * (1 - row['Success Rate'])) / row['Total Launches'])**0.5,\n",
    "        row['Success Rate'] + 1.96 * ((row['Success Rate'] * (1 - row['Success Rate'])) / row['Total Launches'])**0.5,\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "contingency_table = pd.crosstab(df_balanced['Country'], df_balanced['Launch Success Binary'])\n",
    "\n",
    "# Perform the Chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = (contingency_table - expected) / np.sqrt(expected)\n",
    "\n",
    "# Sort residuals\n",
    "residuals = residuals.sum(axis=1).sort_values(ascending=False)\n",
    "print(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed before, the residual looks to highlight, in this case, that a launch's success is more or less likely to be due to randomness and not due to the country itself. Besides that, we must also remember that confidence intervals are meant to evaluate how consistent the impact of a feature is (in this case, the country).\n",
    "\n",
    "After performing the calculation of confidence intervals for each country, as well as performing a chi-square test and calulating residuals for each one, we understand that:  \n",
    "\n",
    "- If we are only taking into consideration raw success rate, United States is a clear favorite succeed, as it holds a rounded 83% success rate. \n",
    "- However, if we are only taking into consideration both the residuals and the confidence intervals and the consistency, Kazakhstan comes across as the most consistent organization even while not keeping a higher success-rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(\n",
    "    success_rate.index,\n",
    "    success_rate['Success Rate'],\n",
    "    yerr=[\n",
    "        success_rate['Success Rate'] - success_rate['Confidence Interval'].apply(lambda x: x[0]),\n",
    "        success_rate['Confidence Interval'].apply(lambda x: x[1]) - success_rate['Success Rate']\n",
    "    ],\n",
    "    fmt='o', capsize=5, color='skyblue', ecolor='darkblue'\n",
    ")\n",
    "plt.title('Success Rates by Country with 95% Confidence Intervals')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "categorical_columns = [\n",
    "    'Country', 'Country_Code', 'Operator', 'Launch Site',\n",
    "    'Comb Launch Site', 'Company Country', 'Ownership', 'Config',\n",
    "    'Status', 'Rocket Name', 'Rocket Organisation'\n",
    "]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    if col in launch_data.columns:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        launch_data[f'{col}_encoded'] = label_encoders[col].fit_transform(launch_data[col])\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_columns = [\n",
    "    'Launch Hour', 'Launch Month', 'Launch Day', 'Launch Weekday',\n",
    "    'Lat', 'Lon', 'Launch Site Lat', 'Launch Site Lon',\n",
    "    'Operator Lat', 'Operator Lon', 'Rocket Price',\n",
    "    'Rocket Payload to LEO', 'USD/kg to LEO',\n",
    "    'USD/kg to LEO CPI Adjusted', 'Rocket Price CPI Adjusted',\n",
    "    'Liftoff Thrust', 'Payload to GTO', 'Stages', 'Strap-ons',\n",
    "    'Rocket Height', 'Fairing Diameter', 'Fairing Height',\n",
    "    'Missions', 'Successes', 'Partial Failures', 'Failures',\n",
    "    'Success Streak', 'Success Rate', 'Mass', 'Payloads'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = [col for col in numerical_columns if col in launch_data.columns]\n",
    "launch_data[numerical_columns] = scaler.fit_transform(launch_data[numerical_columns].fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_balanced[numerical_columns + ['Launch Success Binary']].corr()\n",
    "correlation_with_target = correlations['Launch Success Binary'].sort_values(ascending=False)\n",
    "\n",
    "# Display correlation results\n",
    "print(\"Correlation with Launch Success Binary:\\n\", correlation_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_corr = correlations.sort_values(by='Launch Success Binary', ascending=False)\n",
    "\n",
    "# Set the figure size to ensure all values fit\n",
    "plt.figure(figsize=(16, 14))  # Adjust the size as needed\n",
    "\n",
    "# Plot the heatmap\n",
    "sb.heatmap(correlations, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_balanced.drop(['Launch Success Binary'], axis=1)\n",
    "target = df_balanced['Launch Success Binary']\n",
    "\n",
    "nmp.unique(target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features,target,test_size=0.1, random_state=42)\n",
    "nmp.unique(y_train, return_counts=True), nmp.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_majority, y_train_majority = resample(x_train[y_train==0], y_train[y_train==0], random_state=42)\n",
    "x_train_minority, y_train_minority = resample(x_train[y_train==1], y_train[y_train==1])\n",
    "\n",
    "x_train = nmp.concatenate((x_train_majority, x_train_minority))\n",
    "y_train = nmp.concatenate((y_train_majority, y_train_minority))\n",
    "\n",
    "nmp.unique(y_train, return_counts=True), nmp.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = setup(data = df_balanced, train_size=0.9, target = 'Launch Success Binary', normalize=True, transformation=True)\n",
    "\n",
    "best = compare_models()\n",
    "\n",
    "results = pull()\n",
    "results\n",
    "plot_model(best, plot='confusion_matrix', plot_kwargs={'percent' : True})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
